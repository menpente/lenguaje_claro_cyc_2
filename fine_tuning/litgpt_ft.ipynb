{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "048974c807e1475ab762aec41732c418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b660149367024bc598d867abd451491f",
              "IPY_MODEL_d3b1b5ca3e0b43d8b0faedb17d9df019",
              "IPY_MODEL_e59e0244b20a4f78bbabd148b912819e"
            ],
            "layout": "IPY_MODEL_235c888d8ee54fe685251b3b4dd7251d"
          }
        },
        "b660149367024bc598d867abd451491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4123de4a40ab4b8ab49d00fc256f7b67",
            "placeholder": "​",
            "style": "IPY_MODEL_2daa2ed35dee4466a829c4925c49711d",
            "value": "Generating train split: "
          }
        },
        "d3b1b5ca3e0b43d8b0faedb17d9df019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29e2b766cd04088a2304fb9d5069095",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ba4e67e342e44aa90b1bf46a6284349",
            "value": 1
          }
        },
        "e59e0244b20a4f78bbabd148b912819e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a8dce54c64448ebd84c5cbc9e66b55",
            "placeholder": "​",
            "style": "IPY_MODEL_d4cfc6f6e7104e9792bef49e30dc970f",
            "value": " 3610/0 [00:00&lt;00:00, 45459.00 examples/s]"
          }
        },
        "235c888d8ee54fe685251b3b4dd7251d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4123de4a40ab4b8ab49d00fc256f7b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2daa2ed35dee4466a829c4925c49711d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a29e2b766cd04088a2304fb9d5069095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3ba4e67e342e44aa90b1bf46a6284349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61a8dce54c64448ebd84c5cbc9e66b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4cfc6f6e7104e9792bef49e30dc970f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frluquba/lenguaje_claro_cyc_2/blob/main/fine_tuning/litgpt_ft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalar la librería de \"datasets\"\n",
        "!pip install datasets -Uq"
      ],
      "metadata": {
        "id": "KC8tg_qcC9AJ",
        "outputId": "cf4aa847-2f95-4fd4-a666-0326c80da5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/474.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m450.6/474.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar repositorio Github con los datos\n",
        "!wget https://raw.githubusercontent.com/google-research-datasets/natural-questions/refs/heads/master/nq_open/NQ-open.dev.jsonl -O NQ-open.dev.jsonl"
      ],
      "metadata": {
        "id": "O1hiTinhDAo_",
        "outputId": "cb93455a-af2b-4372-a3d8-35a0a6ab11c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-23 18:14:52--  https://raw.githubusercontent.com/google-research-datasets/natural-questions/refs/heads/master/nq_open/NQ-open.dev.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 391316 (382K) [text/plain]\n",
            "Saving to: ‘NQ-open.dev.jsonl’\n",
            "\n",
            "\rNQ-open.dev.jsonl     0%[                    ]       0  --.-KB/s               \rNQ-open.dev.jsonl   100%[===================>] 382.14K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-09-23 18:14:52 (8.19 MB/s) - ‘NQ-open.dev.jsonl’ saved [391316/391316]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se abre el fichero con \"open\"\n",
        "# Luego se lee con el método \"read\"\n",
        "with open('NQ-open.dev.jsonl') as f:\n",
        "  lines = f.readlines()"
      ],
      "metadata": {
        "id": "ZJDVnOSUDDm7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "for line in lines:\n",
        "    item = json.loads(line.strip())  # Convertir la cadena JSON en un diccionario\n",
        "    data.append(item) # Añadir los últimos elementos de cada diccionario\n",
        "\n",
        "# Guardar todos los datos en un nuevo archivo JSON\n",
        "with open('output.json', 'w') as f:\n",
        "    for item in data:\n",
        "        f.write(json.dumps(item) + '\\n')"
      ],
      "metadata": {
        "id": "KU_Atz71DFnE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la función \"load_dataset\"\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "g-vi7PPyDHno"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qu_ans_dataset = load_dataset(\"json\", data_files=\"output.json\") # Se carga el archivo json (producido en la última celda)\n",
        "qu_ans_dataset"
      ],
      "metadata": {
        "id": "L83W0tBSDJyS",
        "outputId": "c0c29940-d99f-4d84-97a0-e8132cb3eae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "048974c807e1475ab762aec41732c418",
            "b660149367024bc598d867abd451491f",
            "d3b1b5ca3e0b43d8b0faedb17d9df019",
            "e59e0244b20a4f78bbabd148b912819e",
            "235c888d8ee54fe685251b3b4dd7251d",
            "4123de4a40ab4b8ab49d00fc256f7b67",
            "2daa2ed35dee4466a829c4925c49711d",
            "a29e2b766cd04088a2304fb9d5069095",
            "3ba4e67e342e44aa90b1bf46a6284349",
            "61a8dce54c64448ebd84c5cbc9e66b55",
            "d4cfc6f6e7104e9792bef49e30dc970f"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "048974c807e1475ab762aec41732c418"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'answer'],\n",
              "        num_rows: 3610\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qu_ans_dataset = qu_ans_dataset[\"train\"].train_test_split(test_size=0.2) # Se dividen los datos también en conjunto de test para finalizar la creación del dataset a partir del repositorio de Github\n",
        "qu_ans_dataset"
      ],
      "metadata": {
        "id": "tAzFFr65DMF1",
        "outputId": "3696dbdc-07df-4335-ff4f-bac880306a6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'answer'],\n",
              "        num_rows: 2888\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'answer'],\n",
              "        num_rows: 722\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Convertir el dataset a una lista de diccionarios\n",
        "data_list = qu_ans_dataset['train'].to_dict()\n",
        "\n",
        "# Guardar como archivo JSON\n",
        "import json\n",
        "\n",
        "with open('qu_ans_dataset.json', 'w') as json_file:\n",
        "    json.dump(data_list, json_file, indent=4)"
      ],
      "metadata": {
        "id": "roHqenNXDYlJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5V3Mi10ghUsA",
        "outputId": "deece817-197a-4db9-f9a3-50cf43a6d029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litgpt\n",
            "  Downloading litgpt-0.4.12-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt) (1.26.4)\n",
            "Collecting lightning==2.4.0.dev20240728 (from litgpt)\n",
            "  Downloading lightning-2.4.0.dev20240728-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonargparse>=4.27.6 (from jsonargparse[signatures]>=4.27.6->litgpt)\n",
            "  Downloading jsonargparse-4.32.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.5 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.4.5)\n",
            "Requirement already satisfied: tokenizers>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from litgpt) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.10/dist-packages (from litgpt) (4.66.5)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (2024.6.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (24.1)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading torchmetrics-1.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.4.0.dev20240728->litgpt) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning==2.4.0.dev20240728->litgpt)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.5->litgpt) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.5->litgpt) (2.32.3)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]>=4.27.6->litgpt) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.27.6->litgpt)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt) (3.1.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (3.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.4.0.dev20240728->litgpt) (71.0.4)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.27.6->litgpt) (6.4.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->litgpt) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.5->litgpt) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0.dev20240728->litgpt) (4.0.3)\n",
            "Downloading litgpt-0.4.12-py3-none-any.whl (173 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0.dev20240728-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.7/808.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.32.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading torchmetrics-1.4.2-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typeshed-client, lightning-utilities, jsonargparse, torchmetrics, pytorch-lightning, lightning, litgpt\n",
            "Successfully installed jsonargparse-4.32.1 lightning-2.4.0.dev20240728 lightning-utilities-0.11.7 litgpt-0.4.12 pytorch-lightning-2.4.0 torchmetrics-1.4.2 typeshed-client-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install litgpt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PENDIENTE: PREPARAR CUSTOM DATASET SIGUIENDO UN FORMATO SIMILAR A ESTE\n",
        "\n",
        "\n",
        "[\n",
        "  {\n",
        "    \"instruction\": \"Translate the following English text to French.\",\n",
        "    \"input\": \"Hello, how are you?\",\n",
        "    \"output\": \"Bonjour, comment ça va?\"\n",
        "  },\n",
        "  {\n",
        "    \"instruction\": \"Summarize the following article.\",\n",
        "    \"input\": \"The article discusses the impact of climate change on polar bears...\",\n",
        "    \"output\": \"The article highlights the severe impact of climate change on polar bear populations...\"\n",
        "  }\n",
        "]\n",
        "\n",
        "\n",
        "Podemos crear el dataset en Excel o similar y luego utilizar pandas para guardar como json. El fichero debe llamarse my_custom_dataset.json"
      ],
      "metadata": {
        "id": "35fy6-0dlm6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt finetune microsoft/phi-2 \\\n",
        "  --data JSON \\\n",
        "  --data.json_path qu_ans_dataset.json \\\n",
        "  --data.val_split_fraction 0.1 \\\n",
        "  --out_dir checkpoints/microsoft/phi-2"
      ],
      "metadata": {
        "id": "x0EnqDsYjSzw",
        "outputId": "89b4a61b-cd14-4e6b-b861-62ff9938efd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]\n",
            "\rgeneration_config.json:   0% 0.00/124 [00:00<?, ?B/s]\u001b[A\rgeneration_config.json: 100% 124/124 [00:00<00:00, 559kB/s]\n",
            "\n",
            "\rtokenizer.json:   0% 0.00/2.11M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\rmodel-00002-of-00002.safetensors:   0% 0.00/564M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\rconfig.json:   0% 0.00/735 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\rconfig.json: 100% 735/735 [00:00<00:00, 3.06MB/s]\n",
            "\rFetching 7 files:  14% 1/7 [00:00<00:01,  5.46it/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 7.34k/7.34k [00:00<00:00, 20.0MB/s]\n",
            "\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 16.9MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/5.00G [00:00<01:16, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 10.5M/564M [00:00<00:08, 61.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors.index.json: 100% 35.7k/35.7k [00:00<00:00, 7.49MB/s]\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 21.0M/564M [00:00<00:06, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/5.00G [00:00<01:04, 77.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/5.00G [00:00<00:56, 87.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 41.9M/564M [00:00<00:05, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/5.00G [00:00<00:47, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 62.9M/564M [00:00<00:04, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/5.00G [00:00<00:49, 98.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/5.00G [00:00<00:51, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  15% 83.9M/564M [00:00<00:04, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/5.00G [00:00<00:55, 88.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/5.00G [00:01<00:53, 91.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 105M/564M [00:01<00:04, 93.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 105M/5.00G [00:01<00:53, 91.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 115M/564M [00:01<00:04, 93.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 126M/5.00G [00:01<00:50, 97.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 136M/564M [00:01<00:04, 97.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 147M/564M [00:01<00:04, 98.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 147M/5.00G [00:01<00:46, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 168M/564M [00:01<00:03, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 168M/5.00G [00:01<00:43, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 189M/564M [00:01<00:03, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 189M/5.00G [00:01<00:45, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 210M/564M [00:02<00:03, 101MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 210M/5.00G [00:02<00:48, 99.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 220M/564M [00:02<00:03, 99.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 220M/5.00G [00:02<00:49, 96.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 231M/564M [00:02<00:03, 99.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 231M/5.00G [00:02<00:50, 94.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 241M/564M [00:02<00:03, 94.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 241M/5.00G [00:02<00:50, 94.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 252M/564M [00:02<00:03, 93.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 252M/5.00G [00:03<01:36, 49.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 262M/564M [00:05<00:25, 12.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 262M/5.00G [00:05<06:36, 11.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 273M/564M [00:05<00:19, 15.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 273M/5.00G [00:05<05:02, 15.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 294M/564M [00:05<00:10, 24.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 294M/5.00G [00:06<03:05, 25.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 315M/564M [00:06<00:06, 35.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 315M/5.00G [00:06<02:10, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 336M/564M [00:06<00:04, 47.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 336M/5.00G [00:06<01:38, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  63% 357M/564M [00:06<00:03, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 346M/5.00G [00:06<01:28, 52.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  67% 377M/564M [00:06<00:02, 69.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 367M/5.00G [00:06<01:08, 67.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 398M/564M [00:06<00:02, 81.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 388M/5.00G [00:06<00:58, 79.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 419M/564M [00:06<00:01, 94.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 409M/5.00G [00:07<00:50, 90.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 440M/564M [00:07<00:01, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 430M/5.00G [00:07<00:45, 100MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 461M/564M [00:07<00:00, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 451M/5.00G [00:07<00:43, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  86% 482M/564M [00:07<00:00, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 472M/5.00G [00:07<00:39, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 503M/564M [00:07<00:00, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 493M/5.00G [00:07<00:37, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 524M/564M [00:07<00:00, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 514M/5.00G [00:07<00:37, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 545M/564M [00:07<00:00, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 535M/5.00G [00:08<00:36, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 564M/564M [00:08<00:00, 69.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 556M/5.00G [00:08<00:35, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 577M/5.00G [00:08<00:33, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 598M/5.00G [00:08<00:31, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 619M/5.00G [00:08<00:29, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 640M/5.00G [00:08<00:27, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 661M/5.00G [00:08<00:27, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 682M/5.00G [00:08<00:26, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 703M/5.00G [00:09<00:26, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 724M/5.00G [00:09<00:26, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 744M/5.00G [00:09<00:27, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 765M/5.00G [00:09<00:27, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 786M/5.00G [00:09<00:27, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 807M/5.00G [00:09<00:27, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 828M/5.00G [00:09<00:26, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 849M/5.00G [00:10<00:25, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 870M/5.00G [00:10<00:25, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 891M/5.00G [00:10<00:24, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 912M/5.00G [00:10<00:24, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 933M/5.00G [00:10<00:25, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 954M/5.00G [00:10<00:25, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 975M/5.00G [00:10<00:26, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 996M/5.00G [00:10<00:26, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/5.00G [00:11<00:25, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/5.00G [00:11<00:25, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/5.00G [00:11<00:25, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/5.00G [00:13<02:45, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/5.00G [00:14<02:01, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/5.00G [00:14<01:31, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/5.00G [00:14<01:10, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/5.00G [00:14<00:55, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/5.00G [00:14<00:46, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/5.00G [00:14<00:39, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/5.00G [00:14<00:35, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/5.00G [00:15<00:32, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/5.00G [00:15<00:29, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/5.00G [00:15<00:28, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/5.00G [00:15<00:29, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/5.00G [00:15<00:26, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/5.00G [00:15<00:25, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.37G/5.00G [00:15<00:25, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/5.00G [00:16<00:25, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/5.00G [00:16<00:24, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/5.00G [00:16<00:24, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/5.00G [00:16<00:23, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/5.00G [00:16<00:23, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/5.00G [00:20<03:09, 18.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.52G/5.00G [00:20<02:18, 25.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/5.00G [00:20<01:42, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/5.00G [00:20<01:17, 44.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/5.00G [00:20<00:59, 57.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/5.00G [00:20<00:48, 70.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/5.00G [00:20<00:40, 83.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/5.00G [00:20<00:35, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/5.00G [00:21<00:30, 108MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/5.00G [00:21<00:27, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/5.00G [00:21<00:25, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/5.00G [00:21<00:23, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/5.00G [00:21<00:21, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.77G/5.00G [00:21<00:20, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/5.00G [00:21<00:20, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/5.00G [00:21<00:19, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/5.00G [00:22<00:20, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/5.00G [00:22<00:20, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/5.00G [00:22<00:20, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/5.00G [00:22<00:20, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.92G/5.00G [00:22<00:20, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/5.00G [00:23<00:56, 54.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/5.00G [00:23<00:44, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/5.00G [00:23<00:37, 80.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/5.00G [00:24<00:31, 94.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/5.00G [00:24<00:27, 107MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/5.00G [00:24<00:25, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/5.00G [00:24<00:23, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/5.00G [00:24<00:21, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/5.00G [00:24<00:20, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/5.00G [00:24<00:20, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/5.00G [00:25<00:19, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.17G/5.00G [00:25<00:19, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/5.00G [00:25<00:18, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/5.00G [00:25<00:17, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/5.00G [00:25<00:17, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/5.00G [00:25<00:17, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/5.00G [00:25<00:17, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/5.00G [00:25<00:17, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/5.00G [00:26<00:17, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/5.00G [00:26<00:16, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/5.00G [00:26<00:16, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/5.00G [00:26<00:15, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/5.00G [00:26<00:15, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.42G/5.00G [00:26<00:16, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/5.00G [00:26<00:16, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/5.00G [00:27<00:18, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/5.00G [00:27<00:17, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/5.00G [00:27<00:16, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/5.00G [00:27<00:15, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/5.00G [00:27<00:14, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.57G/5.00G [00:27<00:14, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/5.00G [00:27<00:14, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/5.00G [00:28<00:43, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/5.00G [00:28<00:35, 67.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/5.00G [00:29<00:29, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/5.00G [00:29<00:24, 94.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/5.00G [00:29<00:21, 109MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.72G/5.00G [00:29<00:18, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/5.00G [00:29<00:17, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/5.00G [00:29<00:17, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/5.00G [00:29<00:16, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/5.00G [00:30<00:16, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.82G/5.00G [00:30<00:15, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/5.00G [00:30<00:15, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/5.00G [00:30<00:14, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/5.00G [00:30<00:13, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/5.00G [00:30<00:13, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/5.00G [00:30<00:13, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/5.00G [00:31<00:14, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/5.00G [00:31<00:14, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/5.00G [00:31<00:14, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 3.01G/5.00G [00:31<00:14, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/5.00G [00:31<00:13, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/5.00G [00:31<00:13, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/5.00G [00:31<00:12, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/5.00G [00:32<00:12, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/5.00G [00:32<00:12, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/5.00G [00:32<00:12, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/5.00G [00:32<00:11, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/5.00G [00:32<00:11, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/5.00G [00:32<00:11, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 3.22G/5.00G [00:33<00:38, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/5.00G [00:34<00:29, 58.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/5.00G [00:34<00:23, 72.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/5.00G [00:34<00:19, 86.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/5.00G [00:34<00:17, 99.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/5.00G [00:34<00:14, 112MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/5.00G [00:34<00:13, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.37G/5.00G [00:34<00:12, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/5.00G [00:34<00:11, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/5.00G [00:35<00:11, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/5.00G [00:35<00:10, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/5.00G [00:35<00:10, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.47G/5.00G [00:35<00:09, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/5.00G [00:35<00:09, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/5.00G [00:35<00:09, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/5.00G [00:35<00:09, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/5.00G [00:36<00:09, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/5.00G [00:36<00:09, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/5.00G [00:36<00:08, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.62G/5.00G [00:36<00:08, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/5.00G [00:36<00:08, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/5.00G [00:36<00:08, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/5.00G [00:36<00:08, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/5.00G [00:36<00:08, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/5.00G [00:37<00:08, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/5.00G [00:37<00:07, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.76G/5.00G [00:37<00:07, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/5.00G [00:37<00:07, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/5.00G [00:37<00:06, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/5.00G [00:37<00:06, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/5.00G [00:37<00:06, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.87G/5.00G [00:37<00:06, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/5.00G [00:38<00:06, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.91G/5.00G [00:38<00:06, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/5.00G [00:38<00:06, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/5.00G [00:38<00:06, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/5.00G [00:38<00:09, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/5.00G [00:38<00:08, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 4.02G/5.00G [00:39<00:07, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/5.00G [00:39<00:07, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.06G/5.00G [00:39<00:06, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/5.00G [00:39<00:06, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/5.00G [00:39<00:08, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.12G/5.00G [00:39<00:07, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/5.00G [00:40<00:06, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.16G/5.00G [00:40<00:05, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/5.00G [00:40<00:05, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/5.00G [00:40<00:05, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/5.00G [00:40<00:05, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/5.00G [00:40<00:04, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.27G/5.00G [00:40<00:04, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/5.00G [00:40<00:04, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.31G/5.00G [00:41<00:04, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/5.00G [00:41<00:03, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/5.00G [00:41<00:04, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/5.00G [00:41<00:04, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/5.00G [00:41<00:04, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.41G/5.00G [00:41<00:03, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/5.00G [00:41<00:03, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.46G/5.00G [00:42<00:03, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/5.00G [00:42<00:03, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/5.00G [00:42<00:03, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.52G/5.00G [00:42<00:02, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/5.00G [00:42<00:02, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/5.00G [00:42<00:02, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/5.00G [00:42<00:02, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.60G/5.00G [00:43<00:02, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/5.00G [00:43<00:02, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/5.00G [00:43<00:02, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.67G/5.00G [00:43<00:02, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/5.00G [00:43<00:02, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.71G/5.00G [00:43<00:01, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/5.00G [00:43<00:01, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/5.00G [00:44<00:01, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/5.00G [00:44<00:01, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/5.00G [00:44<00:01, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/5.00G [00:44<00:01, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/5.00G [00:44<00:01, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.85G/5.00G [00:44<00:01, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/5.00G [00:44<00:00, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/5.00G [00:46<00:03, 30.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/5.00G [00:48<00:05, 17.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/5.00G [00:48<00:02, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.95G/5.00G [00:49<00:01, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.97G/5.00G [00:49<00:00, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 5.00G/5.00G [00:49<00:00, 101MB/s] \n",
            "Fetching 7 files: 100% 7/7 [00:49<00:00,  7.07s/it]\n",
            "Converting .safetensor files to PyTorch binaries (.bin)\n",
            "checkpoints/microsoft/phi-2/model-00002-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00002-of-00002.bin\n",
            "checkpoints/microsoft/phi-2/model-00001-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00001-of-00002.bin\n",
            "Converting checkpoint files to LitGPT format.\n",
            "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'debug_mode': False,\n",
            " 'dtype': None,\n",
            " 'model_name': None}\n",
            "Loading weights: model-00002-of-00002.bin: 100% 100.0/100 [00:52<00:00,  1.89it/s]\n",
            "Saving converted checkpoint to checkpoints/microsoft/phi-2\n",
            "{'access_token': None,\n",
            " 'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'data': JSON(json_path=PosixPath('qu_ans_dataset.json'),\n",
            "              mask_prompt=False,\n",
            "              val_split_fraction=0.1,\n",
            "              prompt_style=<litgpt.prompts.Alpaca object at 0x79cb4ce56fe0>,\n",
            "              ignore_index=-100,\n",
            "              seed=42,\n",
            "              num_workers=4),\n",
            " 'devices': 1,\n",
            " 'eval': EvalArgs(interval=100,\n",
            "                  max_new_tokens=100,\n",
            "                  max_iters=100,\n",
            "                  initial_validation=False,\n",
            "                  final_validation=True),\n",
            " 'logger_name': 'csv',\n",
            " 'lora_alpha': 16,\n",
            " 'lora_dropout': 0.05,\n",
            " 'lora_head': False,\n",
            " 'lora_key': False,\n",
            " 'lora_mlp': False,\n",
            " 'lora_projection': False,\n",
            " 'lora_query': True,\n",
            " 'lora_r': 8,\n",
            " 'lora_value': True,\n",
            " 'num_nodes': 1,\n",
            " 'optimizer': 'AdamW',\n",
            " 'out_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'precision': None,\n",
            " 'quantize': None,\n",
            " 'seed': 1337,\n",
            " 'train': TrainArgs(save_interval=1000,\n",
            "                    log_interval=1,\n",
            "                    global_batch_size=16,\n",
            "                    micro_batch_size=1,\n",
            "                    lr_warmup_steps=100,\n",
            "                    lr_warmup_fraction=None,\n",
            "                    epochs=5,\n",
            "                    max_tokens=None,\n",
            "                    max_steps=None,\n",
            "                    max_seq_length=None,\n",
            "                    tie_embeddings=None,\n",
            "                    max_norm=None,\n",
            "                    min_lr=6e-05)}\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py:473: UserWarning: Length of split at index 1 is 0. This might result in an empty dataset.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Seed set to 1337\n",
            "Number of trainable parameters: 2,621,440\n",
            "Number of non-trainable parameters: 2,779,683,840\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/litgpt\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/__main__.py\", line 71, in main\n",
            "    CLI(parser_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jsonargparse/_cli.py\", line 119, in CLI\n",
            "    return _run_component(component, init.get(subcommand))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jsonargparse/_cli.py\", line 204, in _run_component\n",
            "    return component(**cfg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/finetune/lora.py\", line 182, in setup\n",
            "    fabric.launch(main, devices, seed, config, data, checkpoint_dir, out_dir, train, eval, optimizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/fabric/fabric.py\", line 843, in launch\n",
            "    return self._wrap_and_launch(function, self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/fabric/fabric.py\", line 929, in _wrap_and_launch\n",
            "    return to_run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/lightning/fabric/fabric.py\", line 934, in _wrap_with_setup\n",
            "    return to_run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/finetune/lora.py\", line 231, in main\n",
            "    fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/finetune/lora.py\", line 283, in fit\n",
            "    longest_seq_length, longest_seq_ix = get_longest_seq_length(ConcatDataset([train_dataloader.dataset, val_dataloader.dataset]))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/finetune/lora.py\", line 451, in get_longest_seq_length\n",
            "    lengths = [len(d[\"input_ids\"]) for d in data]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/finetune/lora.py\", line 451, in <listcomp>\n",
            "    lengths = [len(d[\"input_ids\"]) for d in data]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 350, in __getitem__\n",
            "    return self.datasets[dataset_idx][sample_idx]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/litgpt/data/base.py\", line 78, in __getitem__\n",
            "    example = self.data[idx]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 412, in __getitem__\n",
            "    return self.dataset[self.indices[idx]]\n",
            "KeyError: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt chat checkpoints/microsoft/phi-2"
      ],
      "metadata": {
        "id": "B7IUWXcrnLYx",
        "outputId": "85a6b515-ab76-48da-d8de-49e8a94e4d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'access_token': None,\n",
            " 'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'compile': False,\n",
            " 'max_new_tokens': 50,\n",
            " 'multiline': False,\n",
            " 'precision': None,\n",
            " 'quantize': None,\n",
            " 'temperature': 0.8,\n",
            " 'top_k': 50,\n",
            " 'top_p': 1.0}\n",
            "/usr/local/lib/python3.10/dist-packages/litgpt/utils.py:591: UserWarning: The file size of checkpoints/microsoft/phi-2/lit_model.pth is over 4.2 GB. Using a model with more than 1B parameters on a CPU can be slow, it is recommended to switch to a GPU.\n",
            "  warnings.warn(\n",
            "Now chatting with phi-2.\n",
            "To exit, press 'Enter' on an empty prompt.\n",
            "\n",
            "Seed set to 1234\n",
            ">> Prompt: when did cristiano ronaldo go to manchester united?\n",
            ">> Reply:  Cristiano Ronaldo went to Manchester United in August 2019.\n",
            "\n",
            "Time for inference: 85.89 sec total, 0.14 tokens/sec, 12 tokens\n",
            "\n",
            ">> Prompt: Who wrote \"Mortadelo y Filemon\"?\n",
            ">> Reply:  Jesús García Montero.\n",
            "\n",
            "Exercise 7:\n",
            "Question: In what\n",
            "Time for inference: 98.75 sec total, 0.20 tokens/sec, 20 tokens\n",
            "\n",
            ">> Prompt: \n"
          ]
        }
      ]
    }
  ]
}